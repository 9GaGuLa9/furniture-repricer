"""
Emma Mason Smart Scraper Wrapper v5.2
‚úÖ –°–ø—Ä–æ–±—É—î Algolia API v5.1 (—à–≤–∏–¥–∫–æ, 7000+ —Ç–æ–≤–∞—Ä—ñ–≤)
‚úÖ –Ø–∫—â–æ key expired ‚Üí auto-refresh —á–µ—Ä–µ–∑ Playwright
‚úÖ –Ø–∫—â–æ –Ω–µ –≤–¥–∞–ª–æ—Å—è ‚Üí fallback –Ω–∞ HTML v3 (–ø–æ–≤—ñ–ª—å–Ω–æ, 600+ —Ç–æ–≤–∞—Ä—ñ–≤)
‚úÖ Telegram notifications
‚úÖ –ü–æ–≤–Ω—ñ—Å—Ç—é –∞–≤—Ç–æ–Ω–æ–º–Ω–∏–π –¥–ª—è —Ö–æ—Å—Ç–∏–Ω–≥—É
"""

import logging
import time
import re
from typing import List, Dict, Optional
from datetime import datetime
from pathlib import Path

# –ò–º–ø–æ—Ä—Ç–∏ scrapers
from .emmamason_algolia_v5_1 import EmmaMasonAlgoliaScraperV5_1
from .emmamason_brands import EmmaMasonBrandsScraper as EmmaMasonHTMLScraper

logger = logging.getLogger("emmamason_smart")


class AlgoliaAPIKeyExpired(Exception):
    """Exception –∫–æ–ª–∏ Algolia API key expired"""
    pass


class EmmaMasonSmartScraper:
    """
    –†–æ–∑—É–º–Ω–∏–π wrapper –¥–ª—è Emma Mason scraping
    
    –°—Ç—Ä–∞—Ç–µ–≥—ñ—è:
    1. Algolia API v5.1 (primary) - —à–≤–∏–¥–∫–æ, 7000+ —Ç–æ–≤–∞—Ä—ñ–≤
    2. Auto-refresh API key (—è–∫—â–æ expired)
    3. HTML v3 fallback (—è–∫—â–æ –≤—Å–µ –Ω–µ –ø—Ä–∞—Ü—é—î) - –ø–æ–≤—ñ–ª—å–Ω–æ, 600+ —Ç–æ–≤–∞—Ä—ñ–≤
    """
    
    def __init__(self, config: dict, error_logger=None, telegram_bot=None):
        """
        –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è
        
        Args:
            config: Scraper configuration
            error_logger: ErrorLogger instance (optional)
            telegram_bot: Telegram bot –¥–ª—è notifications (optional)
        """
        self.config = config
        self.error_logger = error_logger
        self.telegram_bot = telegram_bot
        
        self.api_key_last_update = None
        self.scraping_method = None  # 'algolia' –∞–±–æ 'html'
        
        logger.info("="*60)
        logger.info("Emma Mason Smart Scraper v5.2")
        logger.info("="*60)
        logger.info("Strategy: Algolia API ‚Üí Auto-refresh ‚Üí HTML Fallback")
    
    def scrape_all_brands(self) -> List[Dict]:
        """
        –ì–æ–ª–æ–≤–Ω–∏–π –º–µ—Ç–æ–¥ scraping
        
        Returns:
            –°–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä—ñ–≤
        """
        start_time = time.time()
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # –ö–†–û–ö 1: –°–ø—Ä–æ–±—É–≤–∞—Ç–∏ Algolia API v5.1
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        logger.info("\n[STEP 1] Attempting Algolia API v5.1...")
        
        try:
            products = self._try_algolia_api()
            
            if products and len(products) >= 5000:
                duration = time.time() - start_time
                self.scraping_method = 'algolia'
                
                logger.info("="*60)
                logger.info(f"‚úÖ SUCCESS: Algolia API")
                logger.info(f"Products: {len(products)}")
                logger.info(f"Time: {duration:.1f}s")
                logger.info("="*60)
                
                self._send_notification(
                    "‚úÖ Emma Mason: Algolia API Success",
                    f"Products: {len(products)}\n"
                    f"Time: {duration:.1f}s\n"
                    f"Method: Algolia API v5.1"
                )
                
                return products
            
            else:
                logger.warning(f"‚ö†Ô∏è  Low product count: {len(products) if products else 0}")
                raise AlgoliaAPIKeyExpired("Possible expired key (low count)")
        
        except AlgoliaAPIKeyExpired as e:
            logger.warning(f"Algolia API key issue detected: {e}")
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # –ö–†–û–ö 2: –°–ø—Ä–æ–±—É–≤–∞—Ç–∏ auto-refresh API key
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            logger.info("\n[STEP 2] Attempting API key auto-refresh...")
            
            if self._try_auto_refresh_api_key():
                logger.info("‚úÖ API key refreshed successfully, retrying Algolia...")
                
                try:
                    products = self._try_algolia_api()
                    
                    if products and len(products) >= 5000:
                        duration = time.time() - start_time
                        self.scraping_method = 'algolia'
                        
                        logger.info("="*60)
                        logger.info(f"‚úÖ SUCCESS: Algolia API (after refresh)")
                        logger.info(f"Products: {len(products)}")
                        logger.info(f"Time: {duration:.1f}s")
                        logger.info("="*60)
                        
                        self._send_notification(
                            "‚úÖ Emma Mason: API Key Auto-Refreshed",
                            f"API key –±—É–ª–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –æ–Ω–æ–≤–ª–µ–Ω–æ!\n\n"
                            f"Products: {len(products)}\n"
                            f"Time: {duration:.1f}s\n"
                            f"Method: Algolia API v5.1"
                        )
                        
                        return products
                
                except Exception as e2:
                    logger.error(f"Algolia failed after refresh: {e2}")
        
        except Exception as e:
            logger.error(f"Algolia API failed: {e}")
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # –ö–†–û–ö 3: Fallback –Ω–∞ HTML v3 scraping
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        logger.warning("\n[STEP 3] Falling back to HTML scraping v3...")
        
        self._send_notification(
            "‚ö†Ô∏è Emma Mason: Fallback to HTML",
            "Algolia API –Ω–µ –ø—Ä–∞—Ü—é—î (–º–æ–∂–ª–∏–≤–æ expired key).\n"
            "Auto-refresh –Ω–µ –≤–¥–∞–≤—Å—è –∞–±–æ Playwright –Ω–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ.\n\n"
            "–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è HTML scraping v3 (–ø–æ–≤—ñ–ª—å–Ω—ñ—à–µ).\n\n"
            "‚ùó –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è: –û–Ω–æ–≤–∏—Ç–∏ Algolia API key –≤—Ä—É—á–Ω—É –¥–ª—è –∫—Ä–∞—â–æ—ó —à–≤–∏–¥–∫–æ—Å—Ç—ñ."
        )
        
        try:
            products = self._try_html_scraping()
            duration = time.time() - start_time
            self.scraping_method = 'html'
            
            logger.info("="*60)
            logger.info(f"‚úÖ SUCCESS: HTML Fallback")
            logger.info(f"Products: {len(products)}")
            logger.info(f"Time: {duration:.1f}s")
            logger.info("="*60)
            
            self._send_notification(
                "‚úÖ Emma Mason: HTML Fallback Success",
                f"Products: {len(products)}\n"
                f"Time: {duration:.1f}s\n"
                f"Method: HTML Scraping v3\n\n"
                f"Note: –ü–æ–≤—ñ–ª—å–Ω—ñ—à–µ –∑–∞ API, –∞–ª–µ –ø—Ä–∞—Ü—é—î.\n"
                f"–î–ª—è –∫—Ä–∞—â–æ—ó —à–≤–∏–¥–∫–æ—Å—Ç—ñ –æ–Ω–æ–≤—ñ—Ç—å API key."
            )
            
            return products
        
        except Exception as e:
            logger.error(f"‚ùå HTML scraping also failed: {e}")
            
            self._send_notification(
                "üö® Emma Mason: CRITICAL ERROR",
                f"Algolia API failed\n"
                f"Auto-refresh failed\n"
                f"HTML scraping failed: {e}\n\n"
                f"‚ùó –ü–û–¢–†–Ü–ë–ù–ê –ù–ï–ì–ê–ô–ù–ê –£–í–ê–ì–ê!"
            )
            
            # Log error
            if self.error_logger:
                self.error_logger.log_error(
                    "EmmaMasonSmartScraper",
                    e,
                    context={'all_methods_failed': True}
                )
            
            return []
    
    def _try_algolia_api(self) -> List[Dict]:
        """
        –°–ø—Ä–æ–±—É–≤–∞—Ç–∏ Algolia API v5.1
        
        Returns:
            –°–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä—ñ–≤
        
        Raises:
            AlgoliaAPIKeyExpired: –Ø–∫—â–æ –∫–ª—é—á expired
            Exception: –Ü–Ω—à—ñ –ø–æ–º–∏–ª–∫–∏
        """
        try:
            scraper = EmmaMasonAlgoliaScraperV5_1(self.config, self.error_logger)
            products = scraper.scrape_all_brands()
            
            # –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if not products:
                raise AlgoliaAPIKeyExpired("No products returned")
            
            if len(products) < 1000:
                logger.warning(f"Low product count: {len(products)} (expected >5000)")
                raise AlgoliaAPIKeyExpired(f"Low count: {len(products)}")
            
            return products
        
        except Exception as e:
            error_str = str(e).lower()
            
            # –î–µ—Ç–µ–∫—Ç—É–≤–∞—Ç–∏ expired key
            if any(keyword in error_str for keyword in [
                '403', 'forbidden', 'invalid api key', 'unauthorized',
                'low count', 'no products'
            ]):
                raise AlgoliaAPIKeyExpired(f"API key issue: {e}")
            
            # –Ü–Ω—à–∞ –ø–æ–º–∏–ª–∫–∞
            raise
    
    def _try_auto_refresh_api_key(self) -> bool:
        """
        –°–ø—Ä–æ–±—É–≤–∞—Ç–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –æ–Ω–æ–≤–∏—Ç–∏ Algolia API key —á–µ—Ä–µ–∑ Playwright
        
        Returns:
            True —è–∫—â–æ —É—Å–ø—ñ—à–Ω–æ
        """
        logger.info("Attempting to auto-refresh API key via Playwright...")
        
        try:
            # –Ü–º–ø–æ—Ä—Ç—É–≤–∞—Ç–∏ Playwright
            try:
                from playwright.sync_api import sync_playwright
            except ImportError:
                logger.error("Playwright not installed!")
                logger.error("Install: pip install playwright")
                logger.error("Then: playwright install chromium")
                return False
            
            # –û—Ç—Ä–∏–º–∞—Ç–∏ –Ω–æ–≤–∏–π –∫–ª—é—á
            new_key = self._fetch_api_key_playwright()
            
            if not new_key:
                logger.error("Failed to fetch new API key")
                return False
            
            # –û–Ω–æ–≤–∏—Ç–∏ –≤ —Ñ–∞–π–ª—ñ
            if self._update_api_key_in_file(new_key):
                self.api_key_last_update = datetime.now()
                logger.info(f"‚úÖ API key updated at {self.api_key_last_update}")
                return True
            
            return False
        
        except Exception as e:
            logger.error(f"Auto-refresh failed: {e}")
            return False
    
    def _fetch_api_key_playwright(self) -> Optional[str]:
        """
        –û—Ç—Ä–∏–º–∞—Ç–∏ –Ω–æ–≤–∏–π API key —á–µ—Ä–µ–∑ Playwright
        
        Returns:
            –ù–æ–≤–∏–π API key –∞–±–æ None
        """
        try:
            from playwright.sync_api import sync_playwright
            
            with sync_playwright() as p:
                browser = p.chromium.launch(headless=True)
                context = browser.new_context()
                page = context.new_page()
                
                api_key = None
                
                def handle_request(request):
                    nonlocal api_key
                    if 'algolia.net' in request.url:
                        headers = request.headers
                        if 'x-algolia-api-key' in headers:
                            api_key = headers['x-algolia-api-key']
                            logger.info(f"‚úÖ Found API key: {api_key[:20]}...")
                
                page.on('request', handle_request)
                
                try:
                    logger.info("Loading emmamason.com...")
                    page.goto('https://emmamason.com/', timeout=30000)
                    page.wait_for_load_state('networkidle')
                    
                    # Trigger search
                    logger.info("Triggering search to get API key...")
                    search = page.locator('input[type="search"], input.search-field').first
                    
                    if search.is_visible():
                        search.fill('furniture')
                        time.sleep(2)
                    
                    time.sleep(1)
                    
                    return api_key
                
                finally:
                    browser.close()
        
        except Exception as e:
            logger.error(f"Playwright error: {e}")
            return None
    
    def _update_api_key_in_file(self, new_key: str) -> bool:
        """
        –û–Ω–æ–≤–∏—Ç–∏ API key –≤ emmamason_algolia_v5_1.py
        
        Args:
            new_key: –ù–æ–≤–∏–π API key
        
        Returns:
            True —è–∫—â–æ —É—Å–ø—ñ—à–Ω–æ
        """
        try:
            file_path = Path(__file__).parent / 'emmamason_algolia_v5_1.py'
            
            # –ß–∏—Ç–∞—Ç–∏ —Ñ–∞–π–ª
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Backup
            backup_path = file_path.with_suffix('.py.backup')
            with open(backup_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            logger.info(f"Created backup: {backup_path}")
            
            # –ó–∞–º—ñ–Ω–∏—Ç–∏ –∫–ª—é—á
            pattern = r'ALGOLIA_API_KEY = "[^"]+"'
            replacement = f'ALGOLIA_API_KEY = "{new_key}"'
            
            new_content = re.sub(pattern, replacement, content)
            
            if new_content == content:
                logger.error("Failed to replace API key (pattern not found)")
                return False
            
            # –ó–∞–ø–∏—Å–∞—Ç–∏
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(new_content)
            
            logger.info(f"‚úÖ API key updated in {file_path}")
            
            return True
        
        except Exception as e:
            logger.error(f"Failed to update file: {e}")
            return False
    
    def _try_html_scraping(self) -> List[Dict]:
        """
        Fallback: HTML scraping v3
        
        Returns:
            –°–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä—ñ–≤
        """
        try:
            # HTML config (–±—ñ–ª—å—à—ñ –∑–∞—Ç—Ä–∏–º–∫–∏ –¥–ª—è bypass Cloudflare)
            html_config = self.config.copy()
            html_config['delay_min'] = 3.0
            html_config['delay_max'] = 6.0
            
            scraper = EmmaMasonHTMLScraper(html_config, self.error_logger)
            products = scraper.scrape_all_brands()
            
            return products
        
        except Exception as e:
            logger.error(f"HTML scraping failed: {e}")
            raise
    
    def _send_notification(self, title: str, message: str):
        """
        –í—ñ–¥–ø—Ä–∞–≤–∏—Ç–∏ Telegram notification
        
        Args:
            title: –ó–∞–≥–æ–ª–æ–≤–æ–∫
            message: –ü–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è
        """
        if not self.telegram_bot:
            logger.debug("Telegram bot not configured")
            return
        
        try:
            full_message = f"*{title}*\n\n{message}"
            
            # –Ø–∫—â–æ —î –º–µ—Ç–æ–¥ send_message
            if hasattr(self.telegram_bot, 'send_message'):
                self.telegram_bot.send_message(full_message)
            # –Ø–∫—â–æ —Ü–µ –ø—Ä–æ—Å—Ç–æ —Ñ—É–Ω–∫—Ü—ñ—è
            elif callable(self.telegram_bot):
                self.telegram_bot(full_message)
            
            logger.info(f"‚úÖ Telegram notification sent: {title}")
        
        except Exception as e:
            logger.error(f"Failed to send notification: {e}")


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Compatibility wrapper –¥–ª—è —ñ—Å–Ω—É—é—á–æ–≥–æ –∫–æ–¥—É
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class EmmaMasonBrandsScraper:
    """
    Compatibility wrapper - –≤–∏–≥–ª—è–¥–∞—î —è–∫ —Å—Ç–∞—Ä–∏–π scraper
    –∞–ª–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î smart wrapper
    """
    
    def __init__(self, config: dict, error_logger=None, telegram_bot=None):
        """
        –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è
        
        Args:
            config: Configuration dict
            error_logger: ErrorLogger instance (optional)
            telegram_bot: Telegram bot (optional)
        """
        self.smart_scraper = EmmaMasonSmartScraper(
            config=config,
            error_logger=error_logger,
            telegram_bot=telegram_bot
        )
    
    def scrape_all_brands(self) -> List[Dict]:
        """
        Scrape –≤—Å—ñ –±—Ä–µ–Ω–¥–∏ (compatibility method)
        
        Returns:
            –°–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä—ñ–≤
        """
        return self.smart_scraper.scrape_all_brands()


if __name__ == "__main__":
    import logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s | %(levelname)-8s | %(message)s',
        datefmt='%H:%M:%S'
    )
    
    config = {
        'delay_min': 0.5,
        'delay_max': 1.5,
        'retry_attempts': 3,
        'timeout': 30,
        'hits_per_page': 1000
    }
    
    print("\n" + "="*60)
    print("SMART SCRAPER TEST")
    print("="*60 + "\n")
    
    scraper = EmmaMasonBrandsScraper(config)
    results = scraper.scrape_all_brands()
    
    print(f"\n‚úÖ RESULT: {len(results)} products")
    print(f"Method: {scraper.smart_scraper.scraping_method}")
